{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torchmetrics","metadata":{"id":"vHCGcatvffiW","outputId":"eb89ca11-f3e5-4432-d8e1-4a51faac462e","execution":{"iopub.status.busy":"2021-12-21T20:17:47.049767Z","iopub.execute_input":"2021-12-21T20:17:47.050505Z","iopub.status.idle":"2021-12-21T20:17:55.108819Z","shell.execute_reply.started":"2021-12-21T20:17:47.050460Z","shell.execute_reply":"2021-12-21T20:17:55.107975Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# from google.colab import drive\n\n# drive.mount('/content/gdrive/')\n\n# %cd /content/gdrive/MyDrive/Colab Notebooks/university","metadata":{"id":"B54ta0V5HOsc","outputId":"f1421dc6-b39a-4543-a4ec-51d3fb3aad76","execution":{"iopub.status.busy":"2021-12-21T20:17:55.111894Z","iopub.execute_input":"2021-12-21T20:17:55.112161Z","iopub.status.idle":"2021-12-21T20:17:55.118155Z","shell.execute_reply.started":"2021-12-21T20:17:55.112126Z","shell.execute_reply":"2021-12-21T20:17:55.117402Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n!unzip wiki-news-300d-1M.vec.zip","metadata":{"id":"agsAWnJaaKzL","outputId":"7c92389d-489b-4ad6-c636-a14a8b26c9f7","execution":{"iopub.status.busy":"2021-12-21T20:19:11.056906Z","iopub.execute_input":"2021-12-21T20:19:11.057208Z","iopub.status.idle":"2021-12-21T20:20:02.219407Z","shell.execute_reply.started":"2021-12-21T20:19:11.057177Z","shell.execute_reply":"2021-12-21T20:20:02.218365Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nfrom torchmetrics import Accuracy\n\nfrom nltk.tokenize import word_tokenize, wordpunct_tokenize\nfrom tqdm.auto import tqdm\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\nfrom sklearn.utils import shuffle\n\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')","metadata":{"id":"lktf7Sw0IA_p","execution":{"iopub.status.busy":"2021-12-21T20:17:56.710253Z","iopub.execute_input":"2021-12-21T20:17:56.710522Z","iopub.status.idle":"2021-12-21T20:17:59.577311Z","shell.execute_reply.started":"2021-12-21T20:17:56.710492Z","shell.execute_reply":"2021-12-21T20:17:59.576360Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"data_df = pd.read_csv('../input/fake-and-real-news-dataset/Fake.csv')\ndata_df.head()","metadata":{"id":"XI7Jt2RcHxgy","outputId":"167deab7-5e4d-42a3-e2ce-f8984ec950c7","execution":{"iopub.status.busy":"2021-12-21T20:17:59.581419Z","iopub.execute_input":"2021-12-21T20:17:59.581856Z","iopub.status.idle":"2021-12-21T20:18:01.042370Z","shell.execute_reply.started":"2021-12-21T20:17:59.581822Z","shell.execute_reply":"2021-12-21T20:18:01.041690Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"data_df.subject.unique()","metadata":{"id":"YXVsmU9YIF1b","outputId":"ac02b8aa-e182-4e11-c6bf-a5c00cdbb709","execution":{"iopub.status.busy":"2021-12-21T20:18:01.043781Z","iopub.execute_input":"2021-12-21T20:18:01.044030Z","iopub.status.idle":"2021-12-21T20:18:01.057493Z","shell.execute_reply.started":"2021-12-21T20:18:01.043997Z","shell.execute_reply":"2021-12-21T20:18:01.056494Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"mapper = {cat: n for n, cat in enumerate(data_df.subject.unique())}\n\ndata_df['category'] = data_df.subject.map(mapper)\ndata_df = shuffle(data_df)","metadata":{"id":"VHevkPTYkoMK","execution":{"iopub.status.busy":"2021-12-21T20:18:01.059477Z","iopub.execute_input":"2021-12-21T20:18:01.059739Z","iopub.status.idle":"2021-12-21T20:18:01.074765Z","shell.execute_reply.started":"2021-12-21T20:18:01.059704Z","shell.execute_reply":"2021-12-21T20:18:01.074145Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(data_df.text.tolist(), data_df.category.tolist(), test_size=0.2)","metadata":{"id":"cjTNZaqenFkX","execution":{"iopub.status.busy":"2021-12-21T20:18:01.075953Z","iopub.execute_input":"2021-12-21T20:18:01.076304Z","iopub.status.idle":"2021-12-21T20:18:01.095472Z","shell.execute_reply.started":"2021-12-21T20:18:01.076270Z","shell.execute_reply":"2021-12-21T20:18:01.094838Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"word2freq = {}\ntrain_lengths = []\n\nfor text in tqdm(X_train, desc='Processing train'):\n    \n    words = wordpunct_tokenize(text.lower())\n    train_lengths.append(len(words))\n    \n    for word in words:\n        if word in word2freq:\n            word2freq[word] += 1\n        else:\n            word2freq[word] = 1\n\nfor text in tqdm(X_test, desc='Processing test'):\n    words = wordpunct_tokenize(text.lower())\n    \n    for word in words:\n        if word in word2freq:\n            word2freq[word] += 1\n        else:\n            word2freq[word] = 1\n\nmax_len = max(train_lengths)","metadata":{"id":"aWLo_qOTnUYX","outputId":"fe4072f8-e650-4476-b931-6f743b4301ee","execution":{"iopub.status.busy":"2021-12-21T20:18:01.547609Z","iopub.execute_input":"2021-12-21T20:18:01.548141Z","iopub.status.idle":"2021-12-21T20:18:11.092240Z","shell.execute_reply.started":"2021-12-21T20:18:01.548099Z","shell.execute_reply":"2021-12-21T20:18:11.091417Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"max_len","metadata":{"id":"3dbPB1nFqN_1","outputId":"2888f2a1-6017-4ee7-c1ed-befa3f3e74df","execution":{"iopub.status.busy":"2021-12-21T20:18:11.094140Z","iopub.execute_input":"2021-12-21T20:18:11.094409Z","iopub.status.idle":"2021-12-21T20:18:11.099914Z","shell.execute_reply.started":"2021-12-21T20:18:11.094372Z","shell.execute_reply":"2021-12-21T20:18:11.099054Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"(Эксперименты показали, что это очень много и памяти не хватает - обрежем до 500)","metadata":{"id":"OzJwEV9DA-ir"}},{"cell_type":"code","source":"max_len = 500","metadata":{"id":"7YgiPmhnBE6U","execution":{"iopub.status.busy":"2021-12-21T20:40:34.274228Z","iopub.execute_input":"2021-12-21T20:40:34.274523Z","iopub.status.idle":"2021-12-21T20:40:34.279643Z","shell.execute_reply.started":"2021-12-21T20:40:34.274491Z","shell.execute_reply":"2021-12-21T20:40:34.278646Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"word2index = {'PAD': 0}\nvectors = []\n    \nword2vec_file = open('./wiki-news-300d-1M.vec')\n    \nn_words, embedding_dim = word2vec_file.readline().split()\nn_words, embedding_dim = int(n_words), int(embedding_dim)\n\n# Zero vector for PAD\nvectors.append(np.zeros((1, embedding_dim)))\n\nprogress_bar = tqdm(desc='Read word2vec', total=n_words)\n\nwhile True:\n\n    line = word2vec_file.readline().strip()\n\n    if not line:\n        break\n        \n    current_parts = line.split()\n\n    current_word = ' '.join(current_parts[:-embedding_dim])\n\n    if current_word in word2freq:\n\n        word2index[current_word] = len(word2index)\n\n        current_vectors = current_parts[-embedding_dim:]\n        current_vectors = np.array(list(map(float, current_vectors)))\n        current_vectors = np.expand_dims(current_vectors, 0)\n\n        vectors.append(current_vectors)\n\n    progress_bar.update(1)\n\nprogress_bar.close()\n\nword2vec_file.close()\n\nvectors = np.concatenate(vectors)","metadata":{"id":"KC5-IG0Dq-tf","outputId":"818c55d3-3519-4c31-ce67-57506f6b78c8","execution":{"iopub.status.busy":"2021-12-21T20:40:50.023853Z","iopub.execute_input":"2021-12-21T20:40:50.024119Z","iopub.status.idle":"2021-12-21T20:41:19.980385Z","shell.execute_reply.started":"2021-12-21T20:40:50.024078Z","shell.execute_reply":"2021-12-21T20:41:19.979639Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"vectors.shape[0] == len(word2index)","metadata":{"id":"GYsNZpUotqp1","outputId":"cbc48743-7f2c-41d4-8fb0-8a88ee85867a","execution":{"iopub.status.busy":"2021-12-21T20:41:19.982134Z","iopub.execute_input":"2021-12-21T20:41:19.982385Z","iopub.status.idle":"2021-12-21T20:41:19.988135Z","shell.execute_reply.started":"2021-12-21T20:41:19.982351Z","shell.execute_reply":"2021-12-21T20:41:19.987356Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"class NewsData(Dataset):\n    \n    def __init__(self, x_data, y_data, word2index, max_len, pad_token='PAD', verbose=True):\n        \n        super().__init__()\n        \n        self.x_data = []\n        self.y_data = y_data\n        \n        self.word2index = word2index\n        self.max_len = max_len\n        \n        self.pad_token = pad_token\n        self.pad_index = self.word2index[self.pad_token]\n        \n        self.load(x_data, verbose=verbose)\n        \n    @staticmethod\n    def process_text(text, word2index):\n                \n        words = wordpunct_tokenize(text.lower())\n        words = [token for token in words if token.isalpha()]\n        #words = re.findall('[a-яА-ЯеЁ]+', text.lower())\n        return words\n        \n    def load(self, data, verbose=True):\n        \n        data_iterator = tqdm(data, desc='Loading data', disable=not verbose)\n        \n        for text in data_iterator:\n            \n            words = self.process_text(text, self.word2index)\n            \n            indexed_words = self.indexing(words)\n            \n            self.x_data.append(indexed_words)\n    \n    def indexing(self, tokenized_text):\n        \n        return [self.word2index[word] for word in tokenized_text if word in self.word2index]\n    \n    def padding(self, sequence):\n        \n        # Ограничить длину self.sequence_length\n        # если длина меньше максимально - западить\n\n        if len(sequence)< self.max_len:\n          add_pad = self.max_len - len(sequence)\n          return sequence+[self.pad_index]*add_pad\n        else:\n          return sequence[:self.max_len]\n    \n    def __len__(self):\n        \n        return len(self.x_data)\n    \n    def __getitem__(self, idx):        \n        x = self.x_data[idx]\n        x = self.padding(x)\n        x = torch.Tensor(x).long()        \n        y = self.y_data[idx]\n        \n        return x, y","metadata":{"id":"lDNyVPxSf5O5","execution":{"iopub.status.busy":"2021-12-21T20:41:19.990544Z","iopub.execute_input":"2021-12-21T20:41:19.990921Z","iopub.status.idle":"2021-12-21T20:41:20.005017Z","shell.execute_reply.started":"2021-12-21T20:41:19.990884Z","shell.execute_reply":"2021-12-21T20:41:20.004295Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"train_dataset = NewsData(X_train, y_train, word2index, max_len)\ntrain_iterator = DataLoader(train_dataset, batch_size=128)\n\ntest_dataset = NewsData(X_test, y_test, word2index, max_len)\ntest_iterator = DataLoader(test_dataset, batch_size=128)","metadata":{"id":"ddXZSSvHoEFC","outputId":"462b651f-8327-465c-ec2e-4546becf141e","execution":{"iopub.status.busy":"2021-12-21T21:56:49.380488Z","iopub.execute_input":"2021-12-21T21:56:49.381183Z","iopub.status.idle":"2021-12-21T21:56:58.848066Z","shell.execute_reply.started":"2021-12-21T21:56:49.381145Z","shell.execute_reply":"2021-12-21T21:56:58.847239Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"for x, y in train_iterator:\n    break","metadata":{"id":"oZ7-eYWtwuLf","execution":{"iopub.status.busy":"2021-12-21T21:56:58.849719Z","iopub.execute_input":"2021-12-21T21:56:58.850044Z","iopub.status.idle":"2021-12-21T21:56:58.862902Z","shell.execute_reply.started":"2021-12-21T21:56:58.850005Z","shell.execute_reply":"2021-12-21T21:56:58.862235Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"x","metadata":{"id":"KCSqo7fsz-0w","outputId":"f5943d42-db50-470a-8ab6-d67be617c9c1","execution":{"iopub.status.busy":"2021-12-21T21:56:58.864253Z","iopub.execute_input":"2021-12-21T21:56:58.864729Z","iopub.status.idle":"2021-12-21T21:56:58.870779Z","shell.execute_reply.started":"2021-12-21T21:56:58.864693Z","shell.execute_reply":"2021-12-21T21:56:58.870041Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"y","metadata":{"id":"O5gVDfSW0BRI","outputId":"9b7c6dc3-9059-43fe-c009-d73eb58f69db","execution":{"iopub.status.busy":"2021-12-21T21:56:58.872861Z","iopub.execute_input":"2021-12-21T21:56:58.873460Z","iopub.status.idle":"2021-12-21T21:56:58.880005Z","shell.execute_reply.started":"2021-12-21T21:56:58.873406Z","shell.execute_reply":"2021-12-21T21:56:58.879218Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"class C_LSTM(nn.Module):\n    \n    def __init__(self, matrix_w, params):\n        super().__init__()\n\n        self.add_conv_dropout = params['add_conv_dropout']\n        self.add_lstm_dropout = params['add_lstm_dropout']\n        self.add_conv2 = params['add_conv2']\n        if self.add_conv2:\n            self.lstm_input = 2*params['filter_num']\n        else:\n            self.lstm_input = params['filter_num']\n\n        self.embedding = torch.nn.Embedding.from_pretrained(torch.Tensor(matrix_w), freeze=False)\n\n        self.conv2 = nn.Conv1d(in_channels=matrix_w.shape[1], out_channels=params['filter_num'], kernel_size=2)\n        self.conv3 = nn.Conv1d(in_channels=matrix_w.shape[1], out_channels=params['filter_num'], kernel_size=3)\n\n        self.relu = nn.ReLU()\n        self.lstm = nn.LSTM(input_size=self.lstm_input, hidden_size=params['lstm_dim'], num_layers=1, batch_first=True)\n\n        self.linear = nn.Linear(in_features=params['lstm_dim'], out_features=6)\n        self.dropout = nn.Dropout(p=0.5)\n\n    \n    def forward(self, text):\n      embedded = self.relu(self.embedding(text))\n      embedded = embedded.transpose(1,2)\n\n      if self.add_conv_dropout:\n        embedded = self.dropout(embedded)\n\n      #  feature_map.shape = batch_size*out_channels*seq_len\n      feature_map = self.relu(self.conv3(embedded))\n\n      if self.add_conv2:\n        feature_map_2 = self.relu(self.conv2(embedded))\n        max_conv_len = min(feature_map.shape[2], feature_map_2.shape[2])\n        feature_map = torch.cat((feature_map[ : , : , :max_conv_len-1], feature_map_2[ : , : , :max_conv_len-1]), dim=1)\n\n      #  out_channels -> number of x features (input_size)\n      #  seq_len -> seq_len\n\n      _, (h_t, c_t) = self.lstm(feature_map.transpose(1,2))\n\n      if self.add_lstm_dropout:\n        h_t = self.dropout(h_t)\n      \n      output = self.linear(h_t.squeeze())\n\n      return output\n      ","metadata":{"id":"Crm8Cnp_Kp92","execution":{"iopub.status.busy":"2021-12-21T21:54:39.033319Z","iopub.execute_input":"2021-12-21T21:54:39.033904Z","iopub.status.idle":"2021-12-21T21:54:39.046494Z","shell.execute_reply.started":"2021-12-21T21:54:39.033864Z","shell.execute_reply":"2021-12-21T21:54:39.045338Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"def run_train_val(train_loader, val_loader, model, optimizer, criterion, n_epochs, device):\n  losses_train = []\n\n  losses_eval = []\n  acc_eval = []\n\n  for epoch in range(n_epochs):\n      progress_bar = tqdm(total=len(train_loader.dataset), desc='Epoch {} train'.format(epoch + 1))\n      epoch_loss = 0\n      model.train()  \n\n      for i, (texts, ys) in enumerate(train_loader): \n          optimizer.zero_grad() \n\n          texts = texts.to(device)\n          ys = ys.to(device)\n          \n          preds = model(texts)\n              \n          loss = criterion(preds.to(device), ys)\n          loss.backward()   \n          optimizer.step() \n          epoch_loss += loss.item() \n\n          if not (i + 1) % int(len(train_loader)/5):\n              progress_bar.set_postfix(train_loss=epoch_loss/(i+1))\n\n          progress_bar.update(len(ys))\n      \n      progress_bar.close()\n      losses_train.append(epoch_loss / len(train_loader))\n\n      progress_bar = tqdm(total=len(val_loader.dataset), desc='Epoch {} test evaluating'.format(epoch + 1))\n      epoch_loss = 0\n      metric = Accuracy()\n      model.eval() \n\n      with torch.no_grad():\n          for i, (texts, ys) in enumerate(val_loader):   \n              texts = texts.to(device)\n          \n              preds = model(texts)\n              \n              loss = criterion(preds.cpu(), ys)     \n              epoch_loss += loss.item()\n              batch_metric = metric(np.argmax(preds.cpu(), axis=1), ys)\n\n              if not (i + 1) % int(len(val_loader)/5):\n                progress_bar.set_postfix(val_loss=epoch_loss/(i+1), val_acc=batch_metric)\n\n              progress_bar.update(len(ys))\n\n      losses_eval.append(epoch_loss / len(val_loader))\n      epoch_acc = metric.compute()\n      acc_eval.append(epoch_acc)\n\n      print('Epoch accuracy: ', epoch_acc)\n    \n  return losses_train, losses_eval, acc_eval      ","metadata":{"id":"wrzFBgoOfreg","execution":{"iopub.status.busy":"2021-12-21T21:45:56.450079Z","iopub.execute_input":"2021-12-21T21:45:56.450538Z","iopub.status.idle":"2021-12-21T21:45:56.463025Z","shell.execute_reply.started":"2021-12-21T21:45:56.450504Z","shell.execute_reply":"2021-12-21T21:45:56.462267Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"def plot_losses(losses_train, losses_eval, acc_eval):\n  fig, ax = plt.subplots(2, figsize=(5, 10))\n  ax[0].plot(losses_train)\n  ax[0].plot(losses_eval)\n  ax[0].set_title('CE loss value')\n  ax[0].set_ylabel('CE loss')\n  ax[0].set_xlabel('epoch')\n  ax[0].legend(['train', 'val'], loc='upper right')\n \n  ax[1].plot(acc_eval)\n  ax[1].set_title('Accuracy value')\n  ax[1].set_ylabel('Accuracy value')\n  ax[1].set_xlabel('epoch')\n   \n  plt.show()","metadata":{"id":"VmN5J4e2iMFP","execution":{"iopub.status.busy":"2021-12-21T21:15:41.827902Z","iopub.execute_input":"2021-12-21T21:15:41.828494Z","iopub.status.idle":"2021-12-21T21:15:41.835230Z","shell.execute_reply.started":"2021-12-21T21:15:41.828447Z","shell.execute_reply":"2021-12-21T21:15:41.834287Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"def run_experiment(params):\n  model = C_LSTM(vectors, params)\n  criterion = torch.nn.CrossEntropyLoss()\n  optimizer = torch.optim.RMSprop(params=model.parameters(), weight_decay=params['weight_decay'])\n\n  model = model.to(device)\n  criterion = criterion.to(device)\n\n  losses_train, losses_eval, acc_eval = run_train_val(train_iterator, test_iterator, model, optimizer, criterion, params['n_epochs'], device)\n  plot_losses(losses_train, losses_eval, acc_eval)","metadata":{"id":"hf5nPh3OhcZi","execution":{"iopub.status.busy":"2021-12-21T21:15:43.429449Z","iopub.execute_input":"2021-12-21T21:15:43.429718Z","iopub.status.idle":"2021-12-21T21:15:43.436303Z","shell.execute_reply.started":"2021-12-21T21:15:43.429687Z","shell.execute_reply":"2021-12-21T21:15:43.435489Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"markdown","source":"Прогоним на дефолтных параметрах - без дропаутов, с одним слоем свертки и размерностями 150","metadata":{}},{"cell_type":"code","source":"params = {}\nparams['add_conv_dropout'] = False\nparams['add_lstm_dropout'] = False\nparams['add_conv2'] = False\nparams['filter_num'] = 150\nparams['lstm_dim'] = 150\nparams['weight_decay'] = 0\nparams['n_epochs'] = 10\n\nrun_experiment(params)","metadata":{"id":"pJGq6EuU0mqH","outputId":"74ccb8de-0b7c-4b9e-9d22-1ea79eae9af4","execution":{"iopub.status.busy":"2021-12-21T21:15:44.400935Z","iopub.execute_input":"2021-12-21T21:15:44.401218Z","iopub.status.idle":"2021-12-21T21:17:08.203232Z","shell.execute_reply.started":"2021-12-21T21:15:44.401186Z","shell.execute_reply":"2021-12-21T21:17:08.202481Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"markdown","source":"Неплохо, добавим один дропаут","metadata":{}},{"cell_type":"code","source":"params = {}\nparams['add_conv_dropout'] = True\nparams['add_lstm_dropout'] = False\nparams['add_conv2'] = False\nparams['filter_num'] = 150\nparams['lstm_dim'] = 150\nparams['weight_decay'] = 0\nparams['n_epochs'] = 10\n\nrun_experiment(params)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T21:17:08.204942Z","iopub.execute_input":"2021-12-21T21:17:08.205311Z","iopub.status.idle":"2021-12-21T21:18:33.650889Z","shell.execute_reply.started":"2021-12-21T21:17:08.205269Z","shell.execute_reply":"2021-12-21T21:18:33.650240Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"markdown","source":"И другой (в статье вроде сказано, что они не используют два одновременно - видимо, тогда теряется слишком много информации)","metadata":{}},{"cell_type":"code","source":"params = {}\nparams['add_conv_dropout'] = False\nparams['add_lstm_dropout'] = True\nparams['add_conv2'] = False\nparams['filter_num'] = 150\nparams['lstm_dim'] = 150\nparams['weight_decay'] = 0\nparams['n_epochs'] = 10\n\nrun_experiment(params)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T22:22:24.898931Z","iopub.execute_input":"2021-12-21T22:22:24.899482Z","iopub.status.idle":"2021-12-21T22:24:31.079554Z","shell.execute_reply.started":"2021-12-21T22:22:24.899418Z","shell.execute_reply":"2021-12-21T22:24:31.078753Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"markdown","source":"Дропаут для ЛСТМ помог больше всех. Попробуем увеличить размерности выходов сверток и ЛСТМ (без дропаута)","metadata":{}},{"cell_type":"code","source":"params = {}\nparams['add_conv_dropout'] = False\nparams['add_lstm_dropout'] = False\nparams['add_conv2'] = False\nparams['filter_num'] = 300\nparams['lstm_dim'] = 300\nparams['weight_decay'] = 0\nparams['n_epochs'] = 10\n\nrun_experiment(params)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T21:23:46.868317Z","iopub.execute_input":"2021-12-21T21:23:46.868754Z","iopub.status.idle":"2021-12-21T21:26:17.112881Z","shell.execute_reply.started":"2021-12-21T21:23:46.868718Z","shell.execute_reply":"2021-12-21T21:26:17.111309Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"markdown","source":"Особо ничего не поменялось, попробуем добавить L2-регуляризацию","metadata":{}},{"cell_type":"code","source":"params = {}\nparams['add_conv_dropout'] = False\nparams['add_lstm_dropout'] = False\nparams['add_conv2'] = False\nparams['filter_num'] = 300\nparams['lstm_dim'] = 300\nparams['weight_decay'] = 0.001\nparams['n_epochs'] = 10\n\nrun_experiment(params)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T22:25:41.901225Z","iopub.execute_input":"2021-12-21T22:25:41.901523Z","iopub.status.idle":"2021-12-21T22:29:00.214378Z","shell.execute_reply.started":"2021-12-21T22:25:41.901489Z","shell.execute_reply":"2021-12-21T22:29:00.213656Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"markdown","source":"Модель как-то очень нестабильно обучается и теряет в качестве. Вернем дропаут и попробуем добавить еще один сверточный слой с другим окном","metadata":{}},{"cell_type":"code","source":"params = {}\nparams['add_conv_dropout'] = True\nparams['add_lstm_dropout'] = True\nparams['add_conv2'] = True\nparams['filter_num'] = 300\nparams['lstm_dim'] = 300\nparams['weight_decay'] = 0\nparams['n_epochs'] = 10\n\nrun_experiment(params)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T21:57:09.686136Z","iopub.execute_input":"2021-12-21T21:57:09.686404Z","iopub.status.idle":"2021-12-21T22:01:53.645217Z","shell.execute_reply.started":"2021-12-21T21:57:09.686374Z","shell.execute_reply":"2021-12-21T22:01:53.644447Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"markdown","source":"Вариант с дропаутом без второй свертки все еще лучше. Попробуем сразу два вида регуляризации","metadata":{}},{"cell_type":"code","source":"params = {}\nparams['add_conv_dropout'] = True\nparams['add_lstm_dropout'] = True\nparams['add_conv2'] = False\nparams['filter_num'] = 300\nparams['lstm_dim'] = 300\nparams['weight_decay'] = 0.001\nparams['n_epochs'] = 10\n\nrun_experiment(params)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T22:29:11.075026Z","iopub.execute_input":"2021-12-21T22:29:11.075625Z","iopub.status.idle":"2021-12-21T22:32:31.710557Z","shell.execute_reply.started":"2021-12-21T22:29:11.075587Z","shell.execute_reply":"2021-12-21T22:32:31.709811Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"markdown","source":"Вообще ниче не обучается нормально и очень низкое качество. Вернемся к лучшей модели, но с увеличенным количеством выходов сверток и лстм","metadata":{}},{"cell_type":"code","source":"params = {}\nparams['add_conv_dropout'] = False\nparams['add_lstm_dropout'] = True\nparams['add_conv2'] = False\nparams['filter_num'] = 300\nparams['lstm_dim'] = 300\nparams['weight_decay'] = 0\nparams['n_epochs'] = 10\n\nrun_experiment(params)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T22:33:42.395004Z","iopub.execute_input":"2021-12-21T22:33:42.395523Z","iopub.status.idle":"2021-12-21T22:36:59.862238Z","shell.execute_reply.started":"2021-12-21T22:33:42.395484Z","shell.execute_reply":"2021-12-21T22:36:59.861575Z"},"trusted":true},"execution_count":123,"outputs":[]},{"cell_type":"markdown","source":"Лучшее не превосходит","metadata":{}},{"cell_type":"markdown","source":"### Выводы и возможные улучшения:\n- во-первых, сам тип данных очень странный, непонятное разделение между классами какое-то, этим и объясняется плохое качество в общем и целом\n- L2-регуляризация негативно сказывается на процессе обучения, дропауты же помогают больше всего (после ЛСТМ)\n- как и у авторов статьи, у нас лучше всего сработал вариант только с одним сверточным слоем\n- лучшим вариантом оказывается архитектура с 150 выходами у лстм и у сверток, увеличение их количества не приводит к лучшим результатам","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}